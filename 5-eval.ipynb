{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hansirui/Briding_incoherence/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-16 06:25:37 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 16.4MB/s]                    \n",
      "2024-06-16 06:25:37 INFO: Downloaded file to /home/hansirui/stanza_resources/resources.json\n",
      "2024-06-16 06:25:37 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-06-16 06:25:38 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| coref     | ontonotes_electra-large   |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-06-16 06:25:42 INFO: Using device: cuda\n",
      "2024-06-16 06:25:42 INFO: Loading: tokenize\n",
      "2024-06-16 06:25:51 INFO: Loading: mwt\n",
      "2024-06-16 06:25:51 INFO: Loading: coref\n",
      "2024-06-16 06:26:06 INFO: Loading: ner\n",
      "2024-06-16 06:26:06 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "with open('character_table.json', 'r', encoding='utf-8') as file:\n",
    "    character_table = json.load(file)\n",
    "\n",
    "\n",
    "import stanza\n",
    "pipe = stanza.Pipeline(\"en\", processors=\"tokenize,coref,ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_Cooccurrence_count(text,Amcs,Bmcs,Cmcs):\n",
    "    output = pipe(text)\n",
    "    output_json = json.loads(str(output))\n",
    "    count = 0\n",
    "    for sentence in output_json:\n",
    "        for mc in Amcs:\n",
    "            for token in sentence:\n",
    "                try:\n",
    "                    mention_inA = mc in token[\"text\"] or (token[\"coref_chains\"] and mc in token[\"coref_chains\"][0][\"representative_text\"])\n",
    "                except:\n",
    "                    continue\n",
    "                if mention_inA:\n",
    "                    break\n",
    "\n",
    "        for mc in Bmcs:\n",
    "            for token in sentence:\n",
    "                try:\n",
    "                    mention_inB = mc in token[\"text\"] or (token[\"coref_chains\"] and mc in token[\"coref_chains\"][0][\"representative_text\"])\n",
    "                except:\n",
    "                    continue\n",
    "                if mention_inB:\n",
    "                    break\n",
    "        if Cmcs:\n",
    "            for mc in Cmcs:\n",
    "                for token in sentence:\n",
    "                    try:\n",
    "                        mention_inC = mc in token[\"text\"] or (token[\"coref_chains\"] and mc in token[\"coref_chains\"][0][\"representative_text\"])\n",
    "                    except:\n",
    "                        continue\n",
    "                    if mention_inC:\n",
    "                        break\n",
    "        else:\n",
    "            mention_inC = False\n",
    "                  \n",
    "        if (mention_inA and mention_inB) or (mention_inA and mention_inC) or (mention_inB and mention_inC):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def get_Sec_metric(results):\n",
    "    count_list = []\n",
    "    for i in trange(len(results)):\n",
    "        aid = results[i]['aid']\n",
    "        bid = results[i]['bid']\n",
    "        cid = results[i]['cid']\n",
    "        outline = results[i]['outline']\n",
    "        response = results[i]['response']\n",
    "\n",
    "        Amcs = character_table[aid]\n",
    "        Bmcs = character_table[bid]\n",
    "\n",
    "        if cid:\n",
    "            Cmcs = character_table[cid]\n",
    "        else:\n",
    "            Cmcs = []\n",
    "                    # if aid == \"9b4b890c-2b0c-42e2-a291-3a6d36eacae6\" and  bid == \"70cb1895-c5d3-4c6a-902a-c37493f83cff\":\n",
    "        #     count = 0\n",
    "        # else:\n",
    "        try:\n",
    "            count = get_Cooccurrence_count(response,Amcs,Bmcs,Cmcs)\n",
    "        except:\n",
    "            print(outline)\n",
    "            print(response)\n",
    "            raise ValueError\n",
    "        count_list.append(count)\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_sentences(tokens_list):\n",
    "    \"\"\"\n",
    "    将Stanza tokenize后的tokens列表转换回句子列表。\n",
    "    :param tokens_list: Stanza tokenize处理后的输出列表\n",
    "    :return: 由句子组成的列表，每个句子为一个字符串\n",
    "    \"\"\"\n",
    "    sentences = []  # 存储还原的句子\n",
    "    current_sentence = \"\"  # 当前正在构建的句子\n",
    "\n",
    "    for token in tokens_list:\n",
    "        # 添加当前token的文本到当前句子，但先不加空格\n",
    "        if token[\"text\"].strip():  # 避免添加空字符串\n",
    "            if current_sentence:  # 如果当前句子非空\n",
    "                # 检查上一个token是否以标点结束，如果是，则不添加额外空格\n",
    "                if not re.match(r'[\\.\\?!]+$', token[\"text\"]) and \\\n",
    "                   not re.match(r'^[\\[\\(\\{\\<\\]\\)\\}\\>]', token[\"text\"]):\n",
    "                    current_sentence += \" \"  # 否则，在新token前添加空格\n",
    "            current_sentence += token[\"text\"]\n",
    "\n",
    "    # 如果current_sentence非空，说明最后一个句子未被加入到sentences中，应将其添加\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hansirui/Briding_incoherence/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def get_mentioned_flag(targeted_sentences,reference_sentence):\n",
    "    targeted_sentences.append(reference_sentence)\n",
    "    embeddings = model.encode(targeted_sentences)\n",
    "    # print(targeted_sentences[-1])\n",
    "    for i in range(len(targeted_sentences)):\n",
    "        similarity_score = 1 - cosine(embeddings[i], embeddings[-1])\n",
    "        # print(targeted_sentences[i])\n",
    "        if similarity_score > 0.5:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# types =[\"a0 a1 B3 a3 a4\", \"a0 B0 a2 B4 a4\",\"a0 B0 C0 a2 B4 C4 a4\",\"a0 B0 a1 B1 a2 B2 a3 B3 a4 B4\"]\n",
    "def get_plot_mentioned(outline,response,type):\n",
    "    output = pipe(response)\n",
    "    output_json = json.loads(str(output))\n",
    "    targeted_sentences =[]\n",
    "    for sentence in output_json:\n",
    "        bfsent = tokens_to_sentences(sentence)\n",
    "        targeted_sentences.extend(bfsent)\n",
    "\n",
    "    flag = True\n",
    "    for outli in outline:\n",
    "        flag = get_mentioned_flag(targeted_sentences,outli) and flag\n",
    "        if not flag:\n",
    "            break\n",
    "    # if type == \"a0 a1 B3 a3 a4\":\n",
    "    #     flag = get_mentioned_flag(targeted_sentences,outline[2])\n",
    "    # elif type == \"a0 B0 a2 B4 a4\":\n",
    "    #     flag1 = get_mentioned_flag(targeted_sentences,outline[1])\n",
    "    #     flag2 = get_mentioned_flag(targeted_sentences,outline[3])\n",
    "    #     flag = flag1 and flag2\n",
    "    # elif type == \"a0 B0 C0 a2 B4 C4 a4\":\n",
    "    #     flag1 = get_mentioned_flag(targeted_sentences,outline[1])\n",
    "    #     flag2 = get_mentioned_flag(targeted_sentences,outline[2])\n",
    "    #     flag3 = get_mentioned_flag(targeted_sentences,outline[4])\n",
    "    #     flag4 = get_mentioned_flag(targeted_sentences,outline[5])\n",
    "    #     flag = flag1 and flag2 and flag3 and flag4\n",
    "    # elif type == \"a0 B0 a1 B1 a2 B2 a3 B3 a4 B4\":\n",
    "    #     flag1 = get_mentioned_flag(targeted_sentences,outline[1])\n",
    "    #     flag2 = get_mentioned_flag(targeted_sentences,outline[3])\n",
    "    #     flag3 = get_mentioned_flag(targeted_sentences,outline[5])\n",
    "    #     flag4 = get_mentioned_flag(targeted_sentences,outline[7])\n",
    "    #     flag5 = get_mentioned_flag(targeted_sentences,outline[9])\n",
    "\n",
    "    #     flag = flag1 and flag2 and flag3 and flag4 and flag5\n",
    "    return flag\n",
    "\n",
    "\n",
    "def get_first_metric(results,type):\n",
    "    mentioned_flag_list = []\n",
    "    for i in trange(len(results)):\n",
    "        outline = results[i]['outline']\n",
    "        response = results[i]['response']\n",
    "        flag = get_plot_mentioned(outline,response,type)\n",
    "        mentioned_flag_list.append(flag)\n",
    "    return mentioned_flag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主线双支线\n",
      "主线支线\n",
      "双主线\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:12<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9846153846153847\n",
      "主线情节点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:13<00:00,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3615384615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "type_match = {\n",
    "    \"主线情节点\": \"a0 a1 B3 a3 a4\",\n",
    "    \"主线支线\": \"a0 B0 a2 B4 a4\",\n",
    "    \"主线双支线\": \"a0 B0 C0 a2 B4 C4 a4\",\n",
    "    \"双主线\": \"a0 B0 a1 B1 a2 B2 a3 B3 a4 B4\"\n",
    "}\n",
    "task_result = \"GPT4/IO/temp_0_7\"\n",
    "for filename in os.listdir(f\"{task_result}_results\"):\n",
    "    file_path = os.path.join(f\"{task_result}_results\", filename)\n",
    "    type_file = file_path.split('/')[-1].split('.')[0]\n",
    "    type = type_match[type_file]\n",
    "    print(type_file)\n",
    "    if type_file == \"主线双支线\":\n",
    "        continue\n",
    "    elif type_file == \"主线支线\":\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        results = []\n",
    "        for line in file:\n",
    "            res = {}\n",
    "            data = json.loads(line.strip())\n",
    "            \n",
    "            aid = data.get('Aid_list')\n",
    "            bid = data.get('Bid_list')\n",
    "            cid = data.get('Cid_list')\n",
    "            outline = data.get('outline')\n",
    "            response = data.get('responses')\n",
    "\n",
    "            res['aid'] = aid\n",
    "            res['bid'] = bid\n",
    "            res['cid'] = cid\n",
    "            res['outline'] = outline\n",
    "            res['response'] = response\n",
    "            results.append(res)\n",
    "\n",
    "        # mentioned_flag_list = get_first_metric(results,type)\n",
    "        count_list = get_Sec_metric(results)\n",
    "        \n",
    "        # output the true ratio in first metric\n",
    "        # print(mentioned_flag_list.count(True)/len(mentioned_flag_list))\n",
    "        # output the average count in second metric\n",
    "        print(sum(count_list)/len(count_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma fell in love with Paul.', \"Paul didn't feel the same for Emma and rejected Emma.\", \"Colleen is helping calm Dina's fears by being supportive.\", \"Emma felt even worse when the authorities wouldn't listen.\", \"Emma walked under a mattress for a year to show everyone Emma's feelings.\"]\n",
      "Emma had always been smitten with Paul, and she finally mustered the courage to confess her feelings to him. But to her dismay, Paul didn't feel the same way and rejected her, leaving Emma heartbroken.\n",
      "\n",
      "As she struggled to cope with the rejection, Emma turned to her friends for support. Dina, who was already anxious about her own problems, began to fear that she too would experience a similar heartbreak. Colleen, sensing Dina's distress, took it upon herself to calm her friend's fears, offering words of encouragement and reassurance.\n",
      "\n",
      "Meanwhile, Emma's pain and frustration only intensified when she tried to report Paul's rejection to the authorities, only to be met with indifference. They didn't take her feelings seriously, and it seemed like no one was willing to listen.\n",
      "\n",
      "Feeling utterly defeated and misunderstood, Emma decided to take a drastic step to prove the intensity of her emotions. She vowed to walk under a mattress for an entire year, a bizarre and attention-grabbing stunt that she hoped would finally make people understand the depth of her feelings.\n",
      "\n",
      "As the days turned into weeks, and the weeks into months, Emma persisted in her unusual protest, slowly becoming a local sensation. People would gather to watch her walk under the mattress, some in awe, others in confusion. But Emma didn't care – she was determined to make her point, even if it meant making a spectacle of herself.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(count_list)):\n",
    "    if count_list[i]==0:\n",
    "        print(results[i]['outline'])\n",
    "        print(results[i]['response'])\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
